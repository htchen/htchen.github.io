<HTML>
<link href="fdme.css" rel="stylesheet" type="text/css">
<HEAD>
	<TITLE>Fast Defocus Map Estimation</TITLE>
</HEAD>
<BODY>
<div class="body" align="justify" style="padding:1em; width:740px; ">
<div align="center">
<h2>
Fast Defocus Map Estimation
</h2>
<h5>
Ding-Jie Chen, <a href="http://www.cs.nthu.edu.tw/~htchen">Hwann-Tzong Chen</a>, and Long-Wen Chang 
</h5>
</div>
<br />
<br />

<div align="center">
	<table cellspacing="0" cellpadding="3" border="0" >
		<tr>
			<td><img src="exp-com1.jpg" height=300 border=0 /></td>
			<td><img src="exp-com2.jpg" height=300 border=0 /></td>
		</tr>
	</table>
</div>

<div>
<dl>
<dt>
<b>Abstract</b>
</dt>
<dd>
This paper presents a fast algorithm for deriving the defocus map from a single image. Existing methods of defocus map estimation often include a pixel-level propagation step to spread the measured sparse defocus cues over the whole image. Since the pixel-level propagation step is time-consuming, we develop an effective method to obtain the whole-image defocus blur using oversegmentation and 
transductive inference. Oversegmentation produces the superpixels and hence greatly reduces the computation costs for subsequent procedures. Transductive inference provides a way to calculate the similarity between superpixels, and thus helps to infer the defocus blur of each superpixel from all other superpixels. The experimental results show that our method is efficient and able to estimate a plausible superpixel-level defocus map from a given single image.
</dl>
   
<div>
<dl>
<dt>
<a name="paper"></a>
<b>Paper</b>
</dt>
<dd>Ding-Jie Chen, Hwann-Tzong Chen, and Long-Wen Chang: <a href="fdme.pdf">Fast Defocus Map Estimation</a>. ICIP 2016. 
</dd>
<dt>
<a name="code"></a>
<b>Code</b>
</dt>
<dd>
<a href="https://github.com/vllab/fast_defocus_map">github</a>
</dd>
</dl>

</div>

<hr>
Last updated: 14 October 2016

</div>

</BODY>
</HTML>
